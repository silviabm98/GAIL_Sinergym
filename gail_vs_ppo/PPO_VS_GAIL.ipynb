{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 11:46:46.748955: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-08 11:46:46.815777: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 11:46:47.737232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# LIBRERIAS NECESARIAS\n",
    "#########################################################################\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import sinergym\n",
    "from sinergym.utils.wrappers import LoggerWrapper\n",
    "import torch\n",
    "\n",
    "import tensorflow as tf\n",
    "from stable_baselines3 import PPO\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "\n",
    "import os\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Variables globales\n",
    "###########################################################################\n",
    "BATCH_SIZE = 28032\n",
    "EPOCHS =100\n",
    "EPISODES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-08 11:46:50,048] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Updating Building model ExternalInterface object if it is not present...\n",
      "[2023-07-08 11:46:50,048] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Updating Building model Site:Location and SizingPeriod:DesignDay(s) to weather and ddy file...\n",
      "[2023-07-08 11:46:50,050] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Updating building model OutPut:Variable and variables XML tree model for BVCTB connection.\n",
      "[2023-07-08 11:46:50,051] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Setting up extra configuration in building model if exists...\n",
      "[2023-07-08 11:46:50,052] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Setting up action definition in building model if exists...\n"
     ]
    }
   ],
   "source": [
    "# Definimos el entorno\n",
    "env = gym.make('Eplus-5Zone-hot-discrete-v1')\n",
    "env = LoggerWrapper(env)\n",
    "\n",
    "# Obtenemos el espacio de estados del entorno\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del modelo PPO y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(policy=\"MlpPolicy\", env=env, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-08 11:46:50,074] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:46:50,216] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f9938107af0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del modelo PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-08 11:46:58,587] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:46:58,588] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:46:58,679] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run2\n",
      "[2023-07-08 11:47:31,569] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:47:31,571] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:47:31,671] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run3\n"
     ]
    }
   ],
   "source": [
    "reward = 0\n",
    "success_num = 0\n",
    "\n",
    "# Por cada episodio\n",
    "for iteration in range(EPISODES):\n",
    "    # Inicializo todas las variables\n",
    "    observations = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    run_policy_steps = 0\n",
    "\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "\n",
    "    # La primera acción de cada episodio se crea con la red neuronal\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "\n",
    "    # --Actualización de variables: ojo no introduzco el estado y accion inicial, solo introduzco los de PPO\n",
    "    observations.append(obs)  # S_0\n",
    "\n",
    "   \n",
    "    # Por cada steps en cada episodio, mientras no se llegue a un\n",
    "    # estado terminal o un estado malo\n",
    "    while terminated != True and truncated != True:\n",
    "        # --Aumentar el numero de steps\n",
    "        run_policy_steps += 1\n",
    "\n",
    "        action, _ = model.predict(obs)\n",
    "\n",
    "        action = int(action)\n",
    "\n",
    "        # --Muevo al Agente al siguiente estado\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # --Actualización de variables\n",
    "        actions.append(action)  # A_i-1\n",
    "        rewards.append(reward)  # R_i-1\n",
    "\n",
    "        # --Si llegamos a un estado final, el juego ha finalizado!!!\n",
    "        # --Se configura el tablero de nuevo\n",
    "        if terminated:\n",
    "            obs = env.reset()\n",
    "            reward = -1\n",
    "            break\n",
    "        else:\n",
    "            observations.append(next_obs)  # O_i\n",
    "            obs = next_obs\n",
    "\n",
    "    # Ver si el episodio ha obtendo una recompensa total igual o\n",
    "    # superior a 195\n",
    "    if sum(rewards) >= 195:\n",
    "        success_num += 1\n",
    "        if success_num >= 100:\n",
    "            break\n",
    "    else:\n",
    "        success_num = 0\n",
    "\n",
    "observations = np.reshape(observations,newshape=[-1] + list(ob_space.shape))\n",
    "\n",
    "actions = np.array(actions).astype(dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A continuación, probamos como actuaría una agente con la política obtenida con PPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-08 11:47:36,650] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:47:36,651] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:47:36,830] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run4\n",
      "[2023-07-08 11:48:12,865] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:48:12,867] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:48:12,980] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run5\n",
      "[2023-07-08 11:48:48,191] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:48:48,192] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:48:48,287] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run6\n",
      "[2023-07-08 11:49:16,641] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:49:16,642] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:49:16,783] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run7\n",
      "[2023-07-08 11:49:49,225] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:49:49,226] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:49:49,326] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run8\n",
      "[2023-07-08 11:50:23,641] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2023-07-08 11:50:23,642] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-07-08 11:50:23,753] EPLUS_ENV_5Zone-hot-discrete-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-5Zone-hot-discrete-v1-res21/Eplus-env-sub_run9\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompensa promedio: -43938.541059728246 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Recompensa promedio: {mean_reward} +/- {std_reward}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
